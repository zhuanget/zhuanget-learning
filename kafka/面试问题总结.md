## 1、讲一下Kafka消息的存储流程

* 先创建一个Topic，创建Topic时可以指定这个Topic的分区数，没有的话就按照配置文件中的全局默认值设置，以及每个分区的副本数，副本数必须不能超过broker个数。
* 生产者生产一条消息后，发送到Kafka的指定Topic，Kafka会将消息以追加的形式添加到其中的某一个partition中，并且生产者根据acks得到响应。
* 存储流程可以再继续了解具体怎么落盘的流程。。。

## 2、Kafka消息不同分区间可以保证有序性吗

Kafka消息在同一分区是按顺序存放的，但是在不同的分区间是不可以保证顺序性的。如果我们程序要保证有序性，可以通过对消息设置相同的key，使得该Topic的消息都发送到同一分区上，由此来保证有序性。或者直接设置该Topic的分区数是1。如果还是要用多个分区，那可以在消息中设置一个递增字段，在程序中根据该字段来保证有序性。

## 3、你程序中用了阻塞队列+定时任务处理，消息如果保证不丢失

首先我们系统是允许消息丢失的，所以这里我没做处理。但是这里如果要做到保证消息不丢失，我有一个方案：因为这里我是收到消息，放入阻塞队列中，就ACK了，所以如果遇到服务挂掉就会造成队列中的消息还没处理，因此而丢失消息，这里我的方案是，我在处理队列时会维护几个值，记录这个队列消息中所属分区的最小偏移量和最大偏移量，因为这个队列中的消息可能来自几个分区的，但每个分区的消息都是有序的，所以只记录最小最大值就行。然后当这批消息处理完后，我将这几个值与redis中原来的值进行对比，如果连得上直接更新最大偏移量，如果连不上，说明有丢失，把丢失区间记录下来，然后如果有需要，再根据丢失区间去拉取相应偏移量的消息过来重新消息即可。

## 4、如何保证消息不重复消费

一个就是要设置取消自动提交，当自己消费处理完消息后再提交，另外就是程序做成幂等的，保证消息一次和消费多次对结果无影响，比如在车辆数据处理那里，我是根据车牌号存入车辆档案表的，即使同样的消息消费多次，我也只会存一条档案记录。

## 5、我看你写了多线程处理消息，具体是怎么做的，是用多个线程去同时监听topic吗

不是的，监听topic的只能是一个线程，我这里多线程处理是在接收到发来的一批消息后，用多个线程去消费这批消息，这样来加快消息消费。这里用了countDownLatch，当多个线程处理完这批消息之后，再ack。

## 6、那多线程消费有没有做线程同步之类的操作

## 6、你项目中车辆的是用了消息队列+定时任务处理的方式，而人的是用了多线程处理，为什么两者设计要不同呢

这里是因为车辆是摄像头采集并结构化后推过来的，是时间分布比较均匀的，用单个消息队列+定时任务处理，实时性不差。而人的并不是采集的数据，而是经过大数据平台处理归档后的数据，而大数据平台并不是这种均匀推送过来的，是每天有几个时间点大量推送过来，而其他时间推的比较少，这样就会造成在它推过来的时候消费不过来，所以就使用了多线程来加速消费。

## 7、使用kafka消息消费的过程中有没有遇到什么难题

## 8、讲一下你的失败重试、全量更新是怎么设计的

## 9、leader副本挂掉后，kafka是怎么做的

## 10、什么情况下会re-balance

## 11、一个broker可以存相同partition的多个副本吗

## 12、如何实现一个消息队列