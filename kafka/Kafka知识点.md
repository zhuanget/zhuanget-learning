# 一、Kafka介绍及一些概念

*这部分在学习完没有及时进行反馈学习，进行总结，造成阅读书本时产生的一些理解丢失了，希望以后不要再这样了，及时地进行反馈学习。*

## 1.1、发布与订阅

发布与订阅模式，也即生产者-消费者模式，将生产者与消费者的数据传递过程分开，即生产者不直接将数据传递给接收者，而是将消息先发送到一个指定的系统，再由该系统对消息的派发进行管理。最简单的实现是用一个队列存放生产者的消息，再由该队列不断地弹出消息供消费者进行消费。

## 1.2、Kafka的概念

### 1.2.1、Kafka介绍

Kafka一般被称为“分布式提交日志”或“分布式流平台”。所谓的日志或者流，表明Kafka是一个数据持久化系统，数据被按顺序持久化到系统中，可按需进行读取。而分布式则说明Kafka是为分布式系统而生，可很好地用于集群部署环境。

### 1.2.2、主题和分区

Kafka的消息通过主题进行分类。主题可以理解为数据库的表，或者文件系统里的文件夹。主题可以被分为若干个分区，一个分区就是一个提交日志。消息以追加的方式写入分区。然后以先入先出的顺序读取。分区是Kafka分布式扩展的关键，通过分区来实现数据的冗余与伸缩性。

### 1.2.3、消息和批次

消息即是数据，可以理解为数据库系统的一条数据行或一条记录。批次表示一组数据，这些消息属于同一个主题和分区。为了提高效率，消息一般是被分批次写入Kafka。按批次传输可以减少网络开销。这里再说明一下，消息会有一个元数据，即键，当消息以一种可控的方式写入不同的分区时，会用到键。最简单的例子就是为键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，为消息选取分区。相同键的消息总是被写入到相同的分区上。一般一个批次的消息就具有相同的键，这样能确保同一批次的消息被写入到同一分区上。

### 1.2.4、生产者与消费者

生产者创建消息。消费者是消费者组的一部分。也就是说，会有一个或者多个消费者共同读取一个主题。**群组保证每个分区只能被一个消费者使用。**消费者与分区之间的映射通常被称为消费者对分区的所有权关系。

### 1.2.5、broker和集群

一个独立的Kafka服务器被称为broker，也就是集群里的一个节点。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。每个集群都有一个broker同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。一个分区从属于一个broker，该broker被称为分区的首领。一个分区可以分配给多个broker，这个时候会发送分区复制。通过该机制为分区提供了消息冗余。也就是说，我们可以为分区指定管理的broker，可以将不同分区分派到不同的broker上，这就实现了分布式存储，同时，对分区指定多个broker，则可以将数据冗余，当某个broker不可用时，能够保证该分区从属的其他broker能够继续提供访问。

Kafka broker默认的消息保留策略是这样的：要么保留一段时间（比如7天），要么保留到消息达到一定大小的字节数。当消息数量达到这些上限时，旧消息就会过期并被删除。主题可以配置自己的保留策略，可以将消息保留到不再使用它们为止。

### 1.2.6、Kafka的好处

* 多个生产者
* 多个消费者，消费者之间互不影响，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。多个消费者可以组成一个群组，它们共享一个消息流，并保证整个群组对每个给定的消息只处理一次。一条消息被同个groupId的消费者消费了就不会再被消费了。
* 基于磁盘的数据存储，消费者可以被关闭，但消息会继续保留在Kafka里，消费者可以从上次中断的地方继续处理消息。
* 伸缩性，对在线集群进行扩展丝毫不影响整体系统的可用性。一个包含多个broker的集群，即使个别broker失效，仍然可以持续地为客户提供服务。要提高集群的容错能力，需要配置较高的复制系数。
* 高性能

# 二、broker及集群配置

安装Kafka需要安装Zookeeper，Kafka使用Zookeeper保存集群的元数据信息和消费者信息。

任何集群系统都离不开的两个优势：

* 负载均衡
* 防单点故障

对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换。内存页和磁盘之间的交换对Kafka各方面的性能都有重大影响。Kafka大量地使用系统页面缓存。

一种避免内存交换的方法是不设置任何交换分区。

# 三、生产者

## 3.1、概念

如果消息成功写入Kafka，就返回一个RecordMetaData对象，它包含了主题和分区信息，以及记录在分区里的偏移量。主题、分区、偏移量，三个重要的概念。

3.1.1、一些比较基本的东西

1）Kafka生产者有三个必选的属性：

* bootstrap.servers：该属性指定broker的地址清单；
* key.serializer：键的序列化，通过指定key.serializer为实现了org.apache.kafka.common.serialization.Serializer接口的类，在传输时生产者会根据该类将键序列化为字节数组；
* value.serializer：同键的序列化，指定了序列化类，在传输时生产者会将值进行序列化为字节数组。

2）发送消息的三种方式：

* 发送并忘记；
* 同步发送；
* 异步发送。

## 3.2、发送消息

发送消息的两个步骤：

* 创建```ProducerRecord```对象，将键值包装好；
* 调用send()方法进行发送。

从生产者的架构图里可以知道，消息首先会放到缓冲区，然后再使用**单独的线程**发送到服务器端。

## 3.3、配置

聚焦几个比较重要的配置项：

### 1、acks

这个也是经常问到的，分为三种情况：acks = 0, 1, -1：

* acks = 0：生产者成功写入消息之前不会等待任何来自服务器的响应。通过设置为0可以获得很高的吞吐量；
* acks = 1：只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应，这个时候的吞吐量取决于使用的是同步发送还是异步发送；
* acks = -1：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。该模式优势是安全，缺点是延迟高。

具体选择哪种配置，需要根据可靠性需求配置。

### 2、buffer.memory

该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息，即前面提到的会先把消息放到缓冲区，再使用单独的线程进行发送。

### 3、compression.type

该参数可以指定发送消息时的压缩算法，默认是不压缩的，但使用压缩可以降低网络传输开销和存储开销。

### 4、retries

生产者从服务器收到的错误有可能是临时性的错误。在这种情况下，retries参数的值决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误。

### 5、batch.size

当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照**字节数计算**。当批次被填满，批次里的所有消息会被发送出去。该值不宜设置太小。

### 6、linger.ms

该参数指定了生产者在发送批次之前等待更多消息加入批次的时间。KafkaProducer会在批次填满或linger.ms达到上限时把批次发送出去。

### 7、max.in.flight.requests.per.connection

该参数指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量。**把它设为1可以保证消息是按照发送的顺序写入到服务器的。**

### 8、timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms

request.timeout.ms指定了生产者在发送数据时等待服务器返回响应的时间，metadata.fetch.timeout.ms指定了生产者在获取元数据（比如目标分区的首领是谁）时等待服务器返回响应的时间。timeout.ms指定了broker等待同步副本返回消息确认的时间。

### 9、max.request.size

该参数用于控制生产者发送的请求大小。它可以指能发送的单个消息的最大值，也可以指单个请求里所有消息总的大小。

### 10、receive.buffer.bytes和send.buffer.bytes

这两个参数分别指定了TCP socket接收和发送数据包的缓冲区大小。

## 3.4、再谈分区

ProducerRecord对象包含了目标主题、键和值，实际可以不指定键，但大多数应用程序会用到键，键的作用是作为消息的附加消息，以及决定消息写入到主题的哪个分区。Kafka会对键进行散列，决定将消息写入到主题对应的分区。拥有相同键的消息将被写到同一个分区。

而如果键值为null，并且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上。分区器使用轮询算法将消息均衡地分布到各个分区上。

# 四、消费者

应用程序使用KafkaConsumer向Kafka订阅主题，并从订阅的主题上接收消息。

## 4.1、概念

4.1.1、消费者和消费者组

消费者用于订阅主题并接收消息，消费者组将消费者进行分组，一个群组里的消费者订阅同个主题，并接收主题一部分分区的消息。

当往消费者组里添加更多的消费者，超过主题的分区数量时，就会有一部分消费者被闲置，不会接收到任何消息，所以，消费者组里的消费者数量设置最好不要超过分区大小。

往群组里增加消费者是横向伸缩消费能力的主要方式。当单个消费者无法跟上数据生成的速度时，通过增加更多的消费者，让它们分担负载，每个消费者只处理部分分区的消息，这就是横向伸缩的主要手段。只要保证每个应用程序有自己的消费者组，就可以让它们获取到主题所有的消息。不同于传统的消息系统，横向伸缩Kafka消费者和消费者组并不会对性能造成负面影响。

4.1.2、消费者组和分区再均衡

**分区再均衡：**在主题发生变化时，会发生分区重分配。分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。

消费者通过向被指派为**群组协调器**的broker（不同的群组可以有不同的协调器）发送**心跳**来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡。

**注：**所谓心跳其实就是每隔一两秒等发送一条指定的消息。

4.2、轮询

一旦消费者订阅了主题，轮询就会处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据，开发者只需要使用一组简单的API来处理从分区返回的数据。

记住下面代码，就能理解整个消费处理步骤：

```java
ConsumerRecords<String, String> records = consumer.poll(100);
for(ConsumerRecord<String, String> record : records) {
    log.info(record.topic() + record.partition() + record.offset() + record.key() + record.value());
}
```

**备注：**

* 传给poll()方法的参数是一个超时时间，用于控制poll()方法的阻塞时间（在消费者的缓冲区里没有可用数据时会发送阻塞）；
* ```ConsumerRecords```实现了```Iterable<ConsumerRecord>```接口，可以看作```ConsumerRecord```的列表；
* ```ConsumerRecord```包含了记录所属主题的信息、记录所在的分区的信息、记录在分区里的偏移量、记录的键值对。

## 4.3、配置

和生产者配置一样，这里记下一些比较重要的属性。

### 1、fetch.min.bytes

该属性指定了消费者从服务器获取记录的最小字节数。broker在收到消费者的数据请求时，如果可用的数据量小于fetch.min.bytes指定的大小，那么它会等到有足够的可用数据时才把它返回给消费者。如果消费者的数量比较多，把该属性的值设置得大一点可以降低broker的工作负载。

### 2、fetch.max.wait.ms

该属性用于指定broker的等待时间，跟fetch.min.bytes是先满足先返回。

### 3、max.partition.fetch.bytes

该属性指定了服务器从每个分区里返回给消费者的最大字节数。也就是说，`KafkaConsumer.poll()`方法从每个分区里返回的记录最多不超过max.partition.fetch.bytes指定的字节。在设置该属性时，另一个需要考虑的因素是消费者处理数据的时间。消费者需要频繁调用poll()方法来避免会话过期和发送分区再均衡，如果单次调用poll()返回的数据太多，消费者需要更多的时间来处理，可能无法及时进行下一个轮询来避免会话过期。如果出现这种情况，可以把max.partition.fetch.bytes值改小，或者延长会话过期时间。

### 4、session.timeout.ms

该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是3s。该属性与heartbeat.interval.ms紧密相关。heartbeat.interval.ms指定了poll()方法向协调器发送心跳的频率，session.timeout.ms则指定了消费者可以多久不发生心跳。所以，一般需要同时修改这两个属性，heartbeat.interval.ms必须比session.timeout.ms小，一般是session.timeout.ms的三分之一。

### 5、auto.offset.reset

该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下（因消费者长时间无效，包含偏移量的记录已经过时并被删除）该作何处理。

### 6、enable.auto.commit

该属性指定了消费者是否自动提交偏移量，默认是true。

### 7、partition.assignment.strategy

该属性指定分区分配策略。属性的值就是类的名字，可以自定义类来自定义策略，默认使用的是RangeAssignor，这个类实现了Range策略。

#### Range：

该策略会把主题的若干个连续的分区分配给消费者。

#### RoundRobin：

该策略把主题的所有分区逐个分配给消费者。如果所有消费者都订阅相同的主题，RoundRobin策略会给所有消费者分配相同数量的分区（或最多就差一个分区）。

### 8、client.id

broker用它来标识从客户端发送过来的消息。

### 9、max.poll.records

该属性用于控制单次调用call()方法能够返回的记录数量。

### 10、receive.buffer.bytes和send.buffer.bytes

socket在读写数据时用到的TCP缓冲区也可以设置大小。

## 4.4、提交和偏移量

**偏移量：**消息在分区里的位置；

**提交：**更新分区当前位置的操作；

消费者往一个叫做_consumer_offset的特殊主题发送消息，消息里包含每个分区的偏移量。如果消费者发生崩溃或者有新的消费者加入群组，就会触发再均衡。消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。如果提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。

### 4.4.1、提交当前偏移量

把enable.auto.commit设为false，使用commitSync()提交偏移量最简单也最可靠，这个API会提交由poll()方法返回的最新偏移量，提交成功后马上返回，如果提交失败就会抛出异常。commitSync()将会提交由poll()返回的最新偏移量，所以在处理完所有记录后要确保调用了commitSync()。

### 4.4.2、异步提交

consumer.commitAsync()、consumer.commitAsync(new OffsetCommitCallback())。回调经常被用于记录提交错误或生成度量指标。

# 五、设计与实现

## 5.1、集群成员关系

在broker启动的时候，它通过创建临时节点把自己的ID注册到Zookeeper。Kafka组件订阅Zookeeper的/brokers/ids路径（broker在Zookeeper上的注册路径），当有broker加入集群或退出集群时，这些组件就可以获得通知。

在完全关闭一个broker之后，如果使用相同的ID启动另一个全新的broker，它会立即加入集群，并拥有与旧broker相同的分区和主题。

## 5.2、控制器

控制器其实就是一个broker，只不过它除了具有一般broker的功能之外，还负责分区首领的选举。集群里第一个启动的broker通过在Zookeeper里创建一个临时节点/controller让自己成为控制器。

每个新选出的控制器通过Zookeeper的条件递增操作获得一个全新的/数值更大的controller epoch。其他broker在知道当前controller epoch后，如果收到由控制器发出的包含较旧epoch的消息，就会忽略它们。

Kafka使用Zookeeper的临时节点来选举控制器，并在节点加入集群或退出集群时通知控制器。控制器负责在节点加入或离开集群时进行分区首领选举。控制器使用epoch来避免脑裂，**脑裂**是指两个节点同时认为自己是当前的控制器。

## 5.3、复制

复制很重要，可以在个别节点失效时仍能保证Kafka的可用性和持久性。

每个broker可以保存成百上千个属于不同主题和分区的副本。副本分为**首领副本**和**跟随者副本**。首领副本处理客户端请求，跟随者副本复制首领副本数据，当首领崩溃时提升上来，从而保障可用性。首领的另一个任务是搞清楚哪个跟随者的状态与自己是一致的。为了与首领保持同步，跟随者向首领发送获取数据的请求，首领将响应消息发给跟随者，请求消息里包含了跟随者想要获取消息的偏移量，而且这些偏移量总是有序的。如果跟随者在10s内没有请求任何消息，或者虽然在请求消息，但在10s内没有请求最新的数据，那么它就会被认为是不同步的。持续请求得到的最新消息副本被称为**同步的副本（ISR）**。(**注：** **AR：**分区中所有的副本(Assigned Replicas)，**ISR：**同步的副本(In-Sync Replicas)，**OSR：**不同步的副本(Out-Sync Replicas))。

跟随者的正常不活跃时间或在成为不同步副本之前的时间是通过replica.lag.time.max.ms参数来配置的。这个时间间隔直接影响着首领选举期间的客户端行为和数据保留机制。

## 5.4、处理请求

broker的大部分工作是处理客户端、分区副本和控制器发给分区首领的请求。broker会在它所监听的每一个端口上运行一个Acceptor线程，这个线程会创建一个连接，并把它交给Processor线程去处理。网络线程负责从客户端获取请求消息，把它们放进请求队列，然后从响应队列获取响应消息，把它们发送给客户端。

如果broker收到一个针对特定分区的请求，而该分区的首领在另一个broker上，那么发送请求的客户端会收到一个“非分区首领”的错误响应。如果客户端收到“非首领”错误，它会在尝试重发请求之前先刷新元数据，因为这个错误说明了客户端正在使用过期的元数据信息，之前的请求被发到了错误的broker上。

### 5.4.1、获取请求

客户端可以指定broker最多可以从一个分区里返回多少数据。因为客户端需要为broker返回的数据分配足够的内存。如果没有这个限制，broker返回的大量数据有可能耗尽客户端的内存。首领在收到请求时，它会先检查请求是否有效，如果客户端请求的是已经被删除的数据，或者请求的偏移量不存在，那么broker将返回一个错误。

Kafka使用**零复制**技术向客户端发送消息，也就是说，Kafka直接把消息从文件（或者更确切的说是Linux文件系统缓存）里发送到网络通道，而不需要经过任何中间缓冲区。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。零复制技术，与其他数据库系统不同，它会把数据直接从文件发送到网络通道，减少数据的复制。客户端除了可以设置broker返回数据的上限，也可以设置下限。在主题消息流量部署很大的情况下，这样可以减少CPU和网络开销。

并不是所有保存在分区首领上的数据都可以被客户端读取，大部分客户端只能读取已经被写入所有同步副本的消息，分区首领知道每个消息会被复制到哪个副本上， 在消息还没有被写入所有同步副本之前，是不会发送给消费者的，尝试获取这些消息的请求会得到空的响应而不是错误。

如果broker间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长。延迟时间可以通过参数replica.lag.time.max.ms来设置，它指定了副本在复制消息时可被允许的最大延迟时间。

## 5.5、物理存储

主要记住一句话，Kafka的基本存储单元是分区。另外，为了帮助broker更快地定位到指定的偏移量，Kafka为每个分区维护了一个索引。索引把偏移量映射到片段文件和偏移量在文件里的位置。

## 5.6、可靠性

### 5.6.1、可靠性保证

Kafka可靠性的保证：

* Kafka可以保证分区消息的顺序；
* 只有当消息被写入分区的所有同步副本时，它才被认为是“已提交”的；
* 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失；
* 消费者只能读取已经提交的消息。

Kafka可以在配置参数上做出权衡，来达到想要的可靠性。这种权衡一般是指消息存储的可靠性和一致性的重要程度与可用性、高吞吐量、低延迟和硬件成本的重要程度之间的权衡。

### 5.6.2、可靠性配置

#### 1、group.id

如果你希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的group.id。

#### 2、auto.offset.reset

这个参数指定了在没有偏移量可提交时或者请求的偏移量在broker上不存在时，消费者会做些什么。

#### 3、enable.auto.commit

开发者可以选择自动或者代码里手动提交偏移量，自动提交的一个最大好处是，在实现消费者逻辑时可以少考虑一些问题。

#### 4、auto.commit.interval.ms

频繁提交会增加额外的开销，但也会降低重复处理消息的概率。

可靠性另外还要记住一点，在设计应用程序时要注意处理消费者的再均衡问题。

## 5.7、复制

Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。把消息写入多个副本可以使Kafka在发生崩溃时仍能保证消息的持久性。