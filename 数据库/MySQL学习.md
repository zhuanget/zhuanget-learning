# 总述

MySQL分为Server层和存储引擎层两部分。

Server层包括连接器、查询缓存、分析器、优化器、执行器等，所有的内置函数，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。

server层主要做的是MySQL功能层面的事情；引擎层负责存储相关的具体事宜。

![MySQL 的逻辑架构图](D:\学习\记录笔记\zhuanget-learning\图片\MySQL 的逻辑架构图.png)

## 连接器

连接器负责跟客户端建立连接、获取权限、维持和管理连接。

```mysql
mysql -h$ip -P$port -u$user -p
```

连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成TCP握手后，连接器就要开始认证身份，这个时候用的就是输入的用户名和密码。

数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。

## 查询缓存

之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。

## 分析器

分析器做两步：

1、词法分析，识别出SQL语句中的字符串分别是什么，代表什么。

2、语法分析，根据词法分析的结果，语法分析器会根据语法规则，判断输入的这个SQL语句是否满足MySQL语法。如果语句不对，就会收到“ You have an error in your SQL syntax ”的错误提醒。

## 优化器

经过了分析器，MySQL在开始执行之前，还要先经过优化器的处理。

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。

## 执行器

MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

开始执行的时候，要先判断一下你对这个表有没有执行查询的权限，如果没有，就会返回没有权限的错误。

如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

```mysql
mysql> select * from T where ID=10;
```

执行器的执行流程是这样的：

1、调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；

2、调用引擎接口取下一行，重复相同的判断逻辑，直到取这个表的最后一行。

3、执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

#### 慢查询日志相关配置

https://blog.csdn.net/Hu_wen/article/details/105096133

# 更新操作

```mysql

mysql> create table T(ID int primary key, c int);
```

更新语句同样会走一遍查询语句的那一套流程。

* 连接数据库；
* 查询缓存清空；
* 分析器知道是这是一条更新语句；
* 优化器决定使用ID这个索引。

不同的是，更新流程还涉及两个重要的日志模块，redo log（重做日志）和binlog（归档日志）。

## redo log

**WAL：**Write-Ahead Logging，关键点：先写日志，再写磁盘。

具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，从头开始写，写到末尾就又回到开头循环写。

![redo_log](D:\学习\记录笔记\zhuanget-learning\图片\redo_log.png)

write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。

## binlog

redo log是InnoDB引擎特有的日志，而binlog是Server层自己的日志。

两种日志有以下3点不同：

1、redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用；

2、redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1”；

3、redo log是循环写的，空间固定会用完；binlog是可以追加写入的。追加写是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

执行update语句的流程：

![update语句执行流程](D:\学习\记录笔记\zhuanget-learning\图片\update语句执行流程.png)

### 两阶段提交

1、先写redo log，处于prepare状态；

2、写入binlog；

3、提交事务，处于commit状态。

redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让两个保持逻辑上的一致。

两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案。分布式系统也要用到两阶段提交来保证事务。

### 补充

redo log记录的是这个物理页“做了什么改动”，具体记录的就是表空间号，数据页号，偏移量，修改了几个字节的值和具体的修改值。

binlog有两种模式，statement格式的话是记sql语句，row格式会记录行的内容，记两条，更新前和更新后都有。

# 事务

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。MySQL是一个支持多引擎的系统，但并不是所有的引擎都支持事务。MyISAM引擎不支持事务，InnoDB支持。

## 隔离性与隔离级别

事务四大特性：ACID，原子性，一致性，隔离性，持久性。

当数据库上有多个事务同时执行的时候，就可能出现脏读、不可重复读、幻读的问题，为了解决这些问题，就有了隔离级别的概念。

隔离越严实，效率越低。

SQL标准的事务隔离级别包括：读未提交、读已提交、可重复读和串行化。

* 读未提交，一个事务还没提交时，它做的变更就能被别的事务看到；
* 读已提交，一个事务提交后，它做的变更才会被其他事务看到；
* 可重复读，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的；
* 串行化，写会加写锁，读会加读锁，当出现读写锁冲突时，后访问的事务必须等前一个事务执行完成，才能继续执行。

简单理解：

读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。

读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。

可重复读：别人改数据的事务已经提交，我在我的事务中也读不到。

串行化：我的事务尚未提交，别人就别想改数据。

再举一个栗子：

```mysql

mysql> create table T(c int) engine=InnoDB;
insert into T(c) values(1);
```

![事务栗子](D:\学习\记录笔记\zhuanget-learning\图片\事务栗子.png)

不同隔离级别下，事务A的不同返回结果，V1、V2、V3的返回值。

* 读未提交，V1 = 2，V2 = 2，V3 = 2；
* 读已提交，V1 = 1，V2 = 2，V3 = 2；
* 可重复读，V1 = 1，V2  = 1，V3 = 2，遵循的要求：事务在执行期间看到的数据前后必须是一致的；
* 串行化，事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看，V1 = 1，V2 = 1，V3 = 2。

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

* 读未提交，没有视图概念，直接返回记录上的最新值；
* 读已提交，视图是在每个SQL语句开始执行的时候创建的；
* 可重复读，视图是在事务启动时创建的，整个事务存在期间都用这个视图；
* 串行化，没有视图概念，直接用加锁的方式来避免并行访问。

Oracle数据库的默认隔离级别是读已提交，MySQL的默认隔离级别是可重复读。

通过show variables like 'transaction_isolation'可以查看当前隔离级别，通过将启动参数transaction_isolation修改可以设置隔离级别。

## 事务隔离的实现

1、在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。

2、回滚日志什么时候删除？回滚日志在不需要的时候才删除。系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。

3、什么时候才不需要了呢？当系统里没有比这个回滚日志更早的read-view的时候。

4、为什么尽量不要使用长事务？长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能回到的回滚记录都必须保留，这就会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。

## 事务的启动方式

1、显式启动事务语句，begin或者start transaction，提交commit，回滚rollback；

2、set autocommit = 0，该命令会把这个线程的自动提交关掉，这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行commit或rollback或断开连接；

3、建议使用方式1，如果考虑多一次交互问题，可以使用commit work and chain 语法。在autocommit = 1的情况下用begin显式启动事务，如果执行commit则提交事务。如果执行commit work and chain则提交事务并自动启动下一个事务。

## 补充

几个问题：

* 事务的概念是什么
* mysql的事务隔离级别读未提交、读已提交、可重复读、串行化各是什么意思
* 读已提交，可重复读是怎么通过视图构建实现的
* 可重复读的使用场景举例？对账的时候应该很有用？
* 事务隔离是怎么通过read-view（读视图）实现的？
* 多版本并发控制的概念是什么，是怎么实现的？
* 使用长事务的弊病？为什么使用长事务可能拖垮整个库？
* 事务的启动方式有哪几种？
* commit work and chain的语法是做什么用的？
* 怎么查询各个表中的长事务？
* 如何避免长事务的出现？

答案详看：https://time.geekbang.org/column/article/68963

# 索引

## 索引的常见模型

哈希表、有序数组和搜索树。

### 哈希表

哈希索引的缺点：哈希索引做区间查询的速度很慢。

哈希表这种结构适用于只有等值查询的场景。

### 有序数组

有序数组在等值查询和范围查询场景中的性能都非常优秀。

缺点：在需要更新数据的时候就麻烦了，往中间插入一个记录必须得挪动后面所有的记录，成本太高。

有序数组索引适用于静态存储引擎。

### 搜索树

N叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中。

1、数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能 从理论上分析出这个数据库的适用场景。

2、索引是在存储引擎层实现的。

## InnoDB的索引模型

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。

1、根据叶子节点的内容，索引类型分为主键索引和非主键索引；

2、主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引。

3、非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引。

基于主键索引和普通索引的查询有什么区别？

* 如果语句是select * from T where ID = 500，集主键查询方式，则只需要搜索ID这棵B+树；
* 如果语句是select * from T where k = 5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。

也就是说，基于非主键索引的查询需要多扫描一课索引树。因此，我们在应用中应该尽量使用主键查询。

### 索引维护

如果插入数据的时候数据页满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。

除了性能外，页分裂操作还影响数据页的利用率。

1、主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

2、从性能和存储空间方面考量，自增主键往往是更合理的选择。

3、适合用业务字段直接做主键的场景：KV场景。

## 覆盖索引

select ID from T where k between 3 and 5.在这个查询里面，索引k已经覆盖了我们的查询要求，我们称为覆盖索引。

由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

索引字段的维护是有代价的，因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。

## 最左前缀原则

B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。

在建立联合索引的时候，如何安排索引内的字段顺序：

第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

## 索引下推

索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

# 锁

数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。

根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。

## 全局锁

加全局读锁，命令：Flush tables with read lock(FTWRL)。

当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

全局锁的典型使用场景是，做全库逻辑备份。

不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。

官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数-single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。

为什么还需要FTWRL呢？一致性读是好，但前提是引擎要支持这个隔离级别。MyISAM这种不支持事务的引擎就需要FTWRL命令了。

single-transaction方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。

既然要全库只读，为什么不使用set global readonly = true的方式呢？

1、在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库；

2、在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发送异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而readonly，如果客户端异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

## 表级锁

MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock, MDL）。

表锁的语法是lock tables ... read/write。与FTWRL类似，可以用unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个栗子

如果在某个线程A中执行lock tables t1 read, t2 write；这个语句，则其他线程写t1、读写t2的语句都会被阻塞。

### MDL

MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

元数据锁是server层的锁，表级锁，主要用于隔离DML和DDL操作之间的干扰。MDL加锁过程是系统自动控制，无法直接干预，读读共享，读写互斥，写写互斥。

当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

* 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查；
* 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

如果某个表上的查询语句频繁，而且客户端与重试机制，也就是说超时后会再起一个新session再请求的话，这个库的线程很快就会爆满。

事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

如何安全地给小表加字段？

首先要解决长事务，事务不提交，就会一直占着MDL锁。在MySQL的information_schema库的innodb_trx表中，你可以查到当前执行中的事务，如果你要做DDL变更的表刚好有长事务在执行，要考虑先暂停DDL，或者kill掉这个长事务。

在alter table语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。

```mysql
ALTER TABLE tbl_name NOWAIT add column ...
ALTER TABLE tbl_name WAIT N add column ...
```

## 行锁

MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，MyISAM引擎就不支持行锁，不支持行锁意味着并发控制只能使用表锁，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的。

行锁是针对数据表中行记录的锁。如事务A更新了一行，事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。

在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是**两阶段锁协议**。

如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

### 死锁与死锁检测

当出现死锁以后，有两种策略：

* 一种策略是，直接进入等待，直到超时。这个超时实际可以通过参数innodb_lock_wait_timeout来设置；
* 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。

主动死锁检测默认值是on，但它是有额外代价的，每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。

### 怎么解决由这种热点行更新导致的性能问题呢

1、一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉；该方法缺点明显，不推荐；

2、控制并发度：并发控制要做在数据库服务端。可以考虑中间件实现；或者修改MySQL源码，基本思路是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。

3、设计层面优化：如分段汇总。

### 补充

1、两阶段锁的概念是什么？对事务使用有什么帮助？

2、死锁的概念是什么？举例说明出现死锁的情况？

3、死锁的处理策略有哪两种？

4、等待超时处理死锁的机制是什么？有什么局限？

5、死锁检测处理死锁的机制是什么？有什么局限？

6、有哪些思路可以解决热点更新导致的并发问题？

# 再谈事务

begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot这个命令。

* 第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；
* 第二种启动方式，一致性视图是在执行start transaction with consistent snapshot时创建的。

在MySQL里，有两个“视图”的概念：

* 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view ...，而它的查询方法与表一样；
* 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC(读提交)和RR(可重复读)隔离级别的实现。

它没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”。

## “快照”在MVCC里是怎么工作的

在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。这个快照是基于整库的。

InnoDB里面每个事务有一个唯一的事务ID，叫做transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。

每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本。并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。

数据表中的一行记录，其实可能有多个版本， 每个版本有自己的row trx_id。

![行状态变更图](D:\学习\记录笔记\zhuanget-learning\图片\行状态变更图.png)

### 回滚日志（undo log）

图中的三个虚线箭头，就是undo log。V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的。比如，需要V2的时候，就是通过V4依次执行U3、U2算出来的。

1、按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见；

2、如果是这个事务自己更新的数据，它自己还是要认的。

3、在实现上，InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的是，启动了但还没提交。

4、数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。

5、这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

6、数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。

![数据版本可见性规则](D:\学习\记录笔记\zhuanget-learning\图片\数据版本可见性规则.png)

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

1、版本未提交，不可见；

2、版本已提交，但是是在视图创建后提交的，不可见；

3、版本已提交，而且是在视图创建前提交的，可见。

**更新数据update都是先读后写的，而这个读，只能读当前的值，称为“当前读”。**

除了update语句外，select 语句如果加锁，也是当前读。

可重复读的核心就是一致性读；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：

* 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
* 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。